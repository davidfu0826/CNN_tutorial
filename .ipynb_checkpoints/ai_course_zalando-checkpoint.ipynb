{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aHH5GePkKcEc"
   },
   "source": [
    "# BASIC INFORMATION (ReadMe)\n",
    "**1.  About Jupyter Notebook and Google Colab**\n",
    "- Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning etc.\n",
    "- Google Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud. \n",
    "\n",
    "**2.   About this lab**\n",
    "\n",
    "- In this lab we will explore and use Zalando's article images dataset called Fasion-MNIST. Each image in the dataset illustrates a certain article e.g. sneaker, T-shirt or dress.\n",
    "\n",
    "\n",
    "- The goal is to classify the type of article given only the image. We will work mainly with the **convolutional neural network**. ML pipeline outlined in the theory part of the course will be followed. \n",
    "\n",
    "\n",
    "**3.  How to save own version of the Jupyter notebook**\n",
    "\n",
    "- Go to File and choose \"Save a copy in Drive\". This will save your code notebook on your Google Drive.\n",
    "\n",
    "**4.   How to run/execute cell of code**\n",
    "\n",
    "- Alt 1: Ctrl+Enter tab through the code.\n",
    "- Alt 2: Shift+Enter tab through the code.\n",
    "- Alt 3:  Mark the cell,  press \"Run\" button on the left side of the cell.\n",
    "\n",
    "\n",
    "**5.  More info about dataset**\n",
    " - Data source: https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/\n",
    "\n",
    " - Image labels in the dataset:\n",
    "1. T-shirt/top\n",
    "2. Trouser\n",
    "3. Dress\n",
    "4. Coat\n",
    "5. Sandal\n",
    "6. Shirt\n",
    "7. Sneaker\n",
    "8. Bag\n",
    "9. Ankle boot\n",
    "10. Pullover\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "98rRWEMaMR5G"
   },
   "source": [
    "# 1) CLONE ENVIRONMENT & IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ouccb67sMroi"
   },
   "source": [
    "## 1.1. Get all the files\n",
    "- Run the below code cell if the notebook is opened in Google Collab. It will clone the github repository to get all necessary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "XC-22oexM7De",
    "outputId": "7f086f70-4e84-4582-cd9e-452a8b57b9ad"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/NordAxon/AI-For-Leaders.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QaUaw6CrNEI9"
   },
   "source": [
    "## 1.2 Import libraries\n",
    "- ML with Python offers a great deal of libraries.\n",
    "- Read about some of the most used: https://hackernoon.com/top-10-libraries-in-python-to-implement-machine-learning-12602cf5dc61\n",
    "- Documentation about libs used in this lab:\n",
    "\n",
    "\n",
    "> - Pandas: https://pandas.pydata.org/pandas-docs/stable/index.html <br>\n",
    "> - Scikit-learn: https://scikit-learn.org/stable/ <br>\n",
    "> - Keras: https://keras.io/\n",
    "\n",
    "- Lets import all the libraries we need to run the code and perform the analysis. Run the below code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "colab_type": "code",
    "id": "eqz_2xquM2OT",
    "outputId": "bc2e2036-ee7a-4525-b07d-9c9164cc9c5d"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", Warning)\n",
    "\n",
    "# For downloading MNIST Zara fashion dataset\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# For data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Machine learning model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Utility functions used in this lab\n",
    "from CNN_tutorial.classification.data_exploration import *\n",
    "from CNN_tutorial.classification.data_preperation import *\n",
    "from CNN_tutorial.classification.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GHt2tu9TNfxo"
   },
   "source": [
    "# 2) DOWNLOAD THE DATASET\n",
    "- Usually a data scientist has to prepare the labeled image dataset beforehand, which might cost alot of money and time.\n",
    "- Luckily for us, many common datasets e.g. MNIST digits, CIFAR10 and Fasion-MNIST are available directly through Machine Learning libraries. \n",
    "- We will use Keras API to directly download the Fasion-MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "0oXqHBCqMqt_",
    "outputId": "abca22eb-f59e-4cb9-d570-95c1c2c1e704"
   },
   "outputs": [],
   "source": [
    "# Loading images\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2xZUt5oSNCLz",
    "outputId": "b1f1c116-3a37-4d5f-a289-e00608674211"
   },
   "outputs": [],
   "source": [
    "# Size of the dataset (X, Y)\n",
    "print ('Number of images and their dimensions: ' + str(train_images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kU6FfDdSRREW"
   },
   "source": [
    "# 3) DATA EXPLORATION\n",
    "In order to create a model which will classify the Zalando articles with great performance we need to determine the *complexity* of the problem firsthand. In other words, we need to understand the dataset and get to know it better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFlqH2pVRbU7"
   },
   "source": [
    "## 3.1 Visualizing dataset\n",
    "- Let's start by visualizing the **pixels** of the images\n",
    "- Run the following code section below to display one sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "colab_type": "code",
    "id": "sKbQCjmA2T0Y",
    "outputId": "4f5b52c2-bb82-48e1-ebe8-46d1ce07aa31"
   },
   "outputs": [],
   "source": [
    "img = train_images[0]\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oDs2MUkh2Ok8"
   },
   "source": [
    "### Assignment 1\n",
    "Now it's your turn! Try to display another sample image. Edit in the cell below.\n",
    "\n",
    "*Hint: Look at the example above and modify it a little.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "colab_type": "code",
    "id": "atiHX4-O6p1W",
    "outputId": "53392252-9cb1-4f02-941c-027950801b44"
   },
   "outputs": [],
   "source": [
    "############# ENTER YOUR SOLUTION BELOW #####################\n",
    "\n",
    "\n",
    "\n",
    "############# ENTER YOUR SOLUTION ABOVE #####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Me02sL18eDp"
   },
   "source": [
    "Next, run the following cell to visualize a grid of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "uJPN1sU6NNih",
    "outputId": "dfdc45d0-d763-4518-908f-4cef5b7982d4"
   },
   "outputs": [],
   "source": [
    "# Assigning each label to the corresponding index for visualization\n",
    "label_to_article = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\"\n",
    "    }\n",
    "\n",
    "# Visualize one image from each class\n",
    "visualize_dataset(train_images, train_labels, label_to_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rBugYXFLdKBx"
   },
   "source": [
    "## 3.2 Image convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PVqQ1iXPgyS_"
   },
   "source": [
    "How does a model *know* that an image of a shoe is a shoe and not a T-shirt? One uses so called **features** to differentiate between different labels. For instance, one feature can be **the amount of horizontal lines** in an image. \n",
    "\n",
    "For image classification, one can **extract features** by peforming a mathematical operation called **convolution** with the help of a **kernel** (sometimes called a **filter**).\n",
    "\n",
    "![Imgur](https://i.imgur.com/op9Maqr.png)\n",
    "\n",
    "If you want to learn more about this operator, you can read more about it [here (aka Sobel Operators)](https://en.wikipedia.org/wiki/Sobel_operator) \n",
    "\n",
    "**Next step:**\n",
    "To illustrate this concept, run the following code to extract all the horizontal lines from an example image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "dIA4-mHO8bFl",
    "outputId": "9bf48a88-4ea0-49f1-d2a8-98575b24b4c3"
   },
   "outputs": [],
   "source": [
    "kernel = [[ 1,  2,  1], \n",
    "          [ 0,  0,  0],\n",
    "          [-1, -2, -1]]\n",
    "\n",
    "example_image = load_example_image(\"CNN_tutorial/images/teaching.jpg\")\n",
    "\n",
    "visualize_convolution(example_image, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IU6oNI79yst2"
   },
   "source": [
    "### ASSIGNMENT 2\n",
    "Now it is your turn! Perform a convolution and extract all vertical lines from samples of our Zalando dataset by **defining the kernel below**.\n",
    "\n",
    "- *Hint: try all these kernels*\n",
    "$$\n",
    "\\begin{bmatrix} 1 & 2 & 1 \\\\ 0 & 0 & 0 \\\\ -1 & -2 & -1 \\end{bmatrix}, \n",
    "\\begin{bmatrix} 1 & 0 & -1 \\\\ 2 & 0 & -2 \\\\ 1 & 0 & -1 \\end{bmatrix}, \n",
    "\\begin{bmatrix} 2 & 1 & 0 \\\\ 1 & 0 & -1 \\\\ 0 & -1 & -2 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 808
    },
    "colab_type": "code",
    "id": "_Qumw9GGseyW",
    "outputId": "ea608318-e71c-49f0-ebe5-acae89445794"
   },
   "outputs": [],
   "source": [
    "##################### EDIT BELOW ############################\n",
    "# EDIT KERNEL HERE (replace all underscores with numbers)\n",
    "kernel_2 = [[ _, _, _], \n",
    "            [ _, _, _],\n",
    "            [ _, _, _]]\n",
    "##################### EDIT ABOVE ############################\n",
    "\n",
    "visualize_convolution_grid(train_images[:4], kernel_2, figsize=(8,14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k_-xxJL1zzEt"
   },
   "source": [
    "### ASSIGNMENT 2 (DISCUSSION):\n",
    "You have now used convolutions with 3x3 kernels. But it is also possible to use larger kernels such as 3x3 and 4x4. Even other shapes such as 2x3 are possible.\n",
    "\n",
    "**Q 2.1** Which of the following three sentences are true?\n",
    "\n",
    "- We can capture more features with larger kernels.\n",
    "- We can capture more features with smaller kernels.\n",
    "- The same amount of features can be captured by both large and small kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ehNwu3kWIruH"
   },
   "source": [
    "### Final remark on convolutions\n",
    "- So how do we determine which kernels/filters to use for optimal classification in our model? **We don't**. \n",
    "- With the help of **gradient descent**, we can train a **convolutional neural network (CNN)** to automatically find good kernels/filters.\n",
    "- Kernels of size 3x3 are the most common choice in CNNs as it is enough for modelling in most tasks. In certain cases, an increase in size may be benefitial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "si4fWk7FTmez"
   },
   "source": [
    "## 3.3 Dimensionality reduction\n",
    "- We would like to answer the question \"*How complex is the dataset in terms of separability?*\".\n",
    "- One way to determine this is to use **dimensionality reduction**. \n",
    "  - In short, dimensionality reduction is a way to *compress* information/data.\n",
    "  - There are many different approaches for this, e.g. *Principal Component Analysis (PCA)* and *T-distributed Stochastic Neighbor Embedding (t-SNE)*. \n",
    "  - With the help of dimensionality reduction, we can visualize the data distribution. In this case, we will use PCA to represent each image as a pair of coordinates **x** and **y**, in order to visualize it in a 2D-grid. \n",
    "\n",
    "- Run the following code section to perform dimensionality reduction on the Fasion-MNIST dataset.\n",
    "\n",
    "- Note: **You dont have to understand the details of PCA in order to use it. Just observe the resulting figure* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "puUTImUKOxEh",
    "outputId": "9f71979c-bd7a-44f2-dc36-a42207c67cb6"
   },
   "outputs": [],
   "source": [
    "# Compute PCA\n",
    "pca = PCA(n_components=2)\n",
    "flattened_img = np.reshape(train_images, [-1, 28*28]) # Flatten the images (2d: 28x28 -> 1d: 841)\n",
    "pca_img = pca.fit_transform(flattened_img) # Compute two of the principal components of all the images\n",
    "\n",
    "# Display results\n",
    "scatter_plot(pca_img, train_labels, label_to_article, title='PCA', nbr_samples=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rsKgUx4zYDUr"
   },
   "source": [
    "### ASSIGNMENT 3:\n",
    "\n",
    "In this assignment you need to **observe the figure above** and **think through the following questions**:\n",
    "\n",
    "**Q 3.1** The classes Sneakers and Sandals are \"similar\" to each other. Are there other classes that are \"similar\"?\n",
    "\n",
    "**Q 3.2** Which classes **can be separated** by a straight line? \n",
    "\n",
    "**Q 3.3** Which classes **cannot be separated** by a straight line?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "93G0nzoYMidE"
   },
   "source": [
    "### ASSIGNMENT 3 ADVANCED (OPTIONAL)\n",
    "Perform the more powerful *t-SNE decomposition* on the Zalando dataset and plot two components of the decomposition.\n",
    "\n",
    "Hints: \n",
    " - Look at the documentation here https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
    " - The images that are stored in the variable ```train_images``` need to be flattened before being passed. See above example where ```reshape``` is used.\n",
    " - It is recommended to use a few images for t-SNE (e.g. ~3000) or else the computation will take too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "cYp034gJSH7e",
    "outputId": "2ec88afe-2fbe-4876-c80d-e40ba7bc3865"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "############ FILL IN YOUR CODE BELOW ##########################\n",
    "\n",
    "\n",
    "\n",
    "############ FILL IN YOUR CODE ABOCE ##########################\n",
    "\n",
    "scatter_plot(tsne_img, train_labels, label_to_article, title='t-SNE', nbr_samples=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_n-zFGH1d46W"
   },
   "source": [
    "# 4) DATA PRE-PROCESSING\n",
    "- Typically a Data Scientist spends 70% of the time doing arduous pre-processing. It can involve i.e. *cleaning datasets*, *balancing imbalanced datasets*, and *denoising images*. In our case, the Fasion-MNIST dataset is already pre-processed for educational/benchmarking purposes.\n",
    "\n",
    "- The images are RGB-encoded have values that range from 0 to 255. To improve performance for our chosen models, we perform **normalization** by dividing all pixels by 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWm4AXI1WUq2"
   },
   "outputs": [],
   "source": [
    "normalized_train_images = train_images/255.\n",
    "normalized_test_images = test_images/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9wMVjdWhcPNq"
   },
   "source": [
    "### ASSIGNMENT 4 (OPTIONAL):\n",
    "- Perform **standardization** of the image dataset.\n",
    "- *Hint: Use the numpy functions ```.mean()``` and ```.std()```*\n",
    "- *Hint 2: Read about [standardization](https://en.wikipedia.org/wiki/Standard_score)*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UuHHIFJvcOaZ"
   },
   "outputs": [],
   "source": [
    "############ FILL IN YOUR CODE BELOW ##########################\n",
    "\n",
    "\n",
    "\n",
    "############ FILL IN YOUR CODE ABOCE ##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IIDE18hQ22Lt"
   },
   "source": [
    "# 5) MODEL TRAINING AND EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2ET2mfuyMRa"
   },
   "source": [
    "## 5.1 Binary Classification: **Logistic Regression**\n",
    "![alt text](https://littleml.files.wordpress.com/2016/06/lr_boundary_linear.png?w=574&h=&crop=1&zoom=2)\n",
    "- Our starting model for binary classification will be the Logistic Regression (The name might suggest a regression model but it is actually a classification model).\n",
    "\n",
    "- We will use all pixel values as features for our model.\n",
    "\n",
    "- **Geometrical interpretation**: Imagine drawing a *straight line* to separate two types of articles in the figure displayed in *Assignment 1*. Keep this image in your head for the next assignment.\n",
    "\n",
    "- In the following table, all the label-article pair for the dataset are displayed again to facilitate for the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ff19NQHcb2M_"
   },
   "source": [
    "\n",
    "\n",
    "    0. \"T-shirt/top\",\n",
    "    1. \"Trouser\",\n",
    "    2. \"Pullover\",\n",
    "    3. \"Dress\",\n",
    "    4. \"Coat\",\n",
    "    5. \"Sandal\",\n",
    "    6. \"Shirt\",\n",
    "    7. \"Sneaker\",\n",
    "    8. \"Bag\",\n",
    "    9. \"Ankle boot\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WnutEBH24nZV"
   },
   "source": [
    "#### Data preperation\n",
    "For binary classification we only need **two classes**. Therefore, we select only the relevant classes in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cYE0P4c5T3yY"
   },
   "outputs": [],
   "source": [
    "# EDIT HERE: Select two classes from the table above\n",
    "first_label = 3 # Dress\n",
    "second_label = 7 # Sneaker\n",
    "\n",
    "# Extract only the images and the labels for Sneakers and Dresses\n",
    "X_train, y_train = prepare_binary_dataset(normalized_train_images, train_labels, first_label, second_label)\n",
    "X_test, y_test = prepare_binary_dataset(normalized_test_images, test_labels, first_label, second_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S513ZLkl3wPz"
   },
   "source": [
    "#### Model selection\n",
    "Then we create the model using *Scikit-Learn* API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-D-VNDah4bnO"
   },
   "outputs": [],
   "source": [
    "linear_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xiaqIikS33gT"
   },
   "source": [
    "#### Model training\n",
    "Only the *training set* is used for training. In other words, the *test set* is left out during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xN1mgLvP2QxY"
   },
   "outputs": [],
   "source": [
    "linear_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WPyT_PDt3914"
   },
   "source": [
    "#### Model evaluation\n",
    "Now the model is evaluated using the test set (which was excluded from training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6vN2oxLl3K3k",
    "outputId": "cc0efaac-7815-4068-e157-69d8db892e05"
   },
   "outputs": [],
   "source": [
    "print(\"############################ MODEL EVALUATION ############################\")\n",
    "train_predictions = linear_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "\n",
    "test_predictions = linear_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"Train accuracy: {100*train_accuracy}%\")\n",
    "print(f\"Test accuracy:  {100*test_accuracy}%\")\n",
    "\n",
    "first_title = label_to_article[first_label]\n",
    "second_title = label_to_article[second_label]\n",
    "print_confusion_matrices(y_test, test_predictions, class_names=[first_title, second_title]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "auo_V6xV4v3g"
   },
   "source": [
    "### ASSIGNMENT 5:\n",
    "**Q 5.1** What test accuracy did we get when classifying between *Dress* and *Sneaker*? \n",
    " \n",
    " <br>\n",
    " \n",
    "Modify the code such that it classifies between the articles *Pullover* and *Coat* in the code cell below.\n",
    "\n",
    "**Q 5.2** *Can you explain why we did not get 100% accuracy when classifying between Coat and Pullover (hint: look at the figure from the PCA visualization)?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJNiukwHUvVr"
   },
   "outputs": [],
   "source": [
    "############ FILL IN YOUR CODE BELOW ##########################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############ FILL IN YOUR CODE ABOCE ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K7kofiC0GRAs",
    "outputId": "2701d2cf-0fcc-4c31-e603-2b5102193bc0"
   },
   "outputs": [],
   "source": [
    "# Evaluation script\n",
    "print(\"############################ MODEL EVALUATION ############################\")\n",
    "train_predictions = linear_model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "\n",
    "test_predictions = linear_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"Train accuracy: {100*train_accuracy}%\")\n",
    "print(f\"Test accuracy:  {100*test_accuracy}%\")\n",
    "\n",
    "first_title = label_to_article[first_label]\n",
    "second_title = label_to_article[second_label]\n",
    "print_confusion_matrices(y_test, test_predictions, class_names=[first_title, second_title]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4WtNIEFx4zBp"
   },
   "source": [
    "## 5.2 Multiclass Classification: **Neural Network (ANN)**\n",
    "Next, we will take advantage of artificial neural networks (ANN)!\n",
    "\n",
    "![title](https://cdn-images-1.medium.com/max/1000/1*DW0Ccmj1hZ0OvSXi7Kz5MQ.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "44rZhl3o46ED"
   },
   "source": [
    "#### Data preperation\n",
    "In contrast to binary classification, we keep all the images as NN can perform multiclass classification. In addition, instead of Scikit-Learn we use *Keras API* for building our model instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5scOGrgp47m8"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_ANN_dataset(normalized_train_images, train_labels)\n",
    "X_test, y_test = prepare_ANN_dataset(normalized_test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r26xbTIX49TK"
   },
   "source": [
    "#### Model selection\n",
    "We use Keras API to build our ANN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "colab_type": "code",
    "id": "GKHUR8FV5ENY",
    "outputId": "2b05186b-7ea9-448e-ac0a-a47fee713708"
   },
   "outputs": [],
   "source": [
    "# Number of nodes in each fully-connected layer\n",
    "nbr_nodes = [4, 4]\n",
    "\n",
    "# Build model\n",
    "model = build_ANN(nbr_nodes=nbr_nodes)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3y8-8w8U5Bzn"
   },
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "eZaZ2QdT4_uN",
    "outputId": "c103323d-e58d-436f-ca0f-0da3ad18ffaf"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwDwqX4z7Jof"
   },
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XKe2XiqC7L6j",
    "outputId": "90a69acc-cd16-4585-e3fa-d79d852ab2c5"
   },
   "outputs": [],
   "source": [
    "print(\"############################ MODEL EVALUATION ############################\")\n",
    "train_predictions = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train.argmax(axis=1), train_predictions.argmax(axis=1))\n",
    "\n",
    "test_predictions = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test.argmax(axis=1), test_predictions.argmax(axis=1))\n",
    "\n",
    "print(f\"Train accuracy: {100*train_accuracy}%\")\n",
    "print(f\"Test accuracy: {100*test_accuracy}%\")\n",
    "print_confusion_matrices(y_test.argmax(axis=1), test_predictions.argmax(axis=1), class_names=label_to_article.values());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0cCZYsQ57aNZ"
   },
   "source": [
    "### ASSIGNMENT 6:\n",
    "Modify the code and try to improve the performance of the ANN model. Then find the answers to these following questions.\n",
    "\n",
    "**Q 6.1.** What happens with the loss for a higher amount of training epochs? \n",
    "\n",
    " \n",
    "\n",
    "**Q 6.2.** What are the results when adding more layers?  \n",
    "\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "**Q 6.3.** What are the results when adding more neurons?  \n",
    "\n",
    " \n",
    " \n",
    "\n",
    "**Q 6.4.** When is there a difference between train and test data in Mean Squared Error? Why is that? \n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "WvrcRt0_ALGt",
    "outputId": "744e4a10-4997-4d81-ea5e-4fbbf277420d"
   },
   "outputs": [],
   "source": [
    "############ FILL IN YOUR CODE BELOW ##########################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############ FILL IN YOUR CODE ABOCE ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "VjjX8__uG2kI",
    "outputId": "8e159940-a163-4b36-bb55-f8f1c47a59eb"
   },
   "outputs": [],
   "source": [
    "# Evaluation script\n",
    "print(\"############################ MODEL EVALUATION ############################\")\n",
    "train_predictions = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train.argmax(axis=1), train_predictions.argmax(axis=1))\n",
    "\n",
    "test_predictions = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test.argmax(axis=1), test_predictions.argmax(axis=1))\n",
    "\n",
    "print(f\"Train accuracy: {100*train_accuracy}%\")\n",
    "print(f\"Test accuracy: {100*test_accuracy}%\")\n",
    "print_confusion_matrices(y_test.argmax(axis=1), test_predictions.argmax(axis=1), class_names=label_to_article.values());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "usp6w_P02603"
   },
   "source": [
    "## 5.3 Multiclass Classification: **Convolutional Neural Network (CNN)**\n",
    "Now, we will take advantage of *convolutional features*!\n",
    "![title](https://i.imgur.com/RYMoJpL.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2masR4w4KUq"
   },
   "source": [
    "#### Data preperation\n",
    "In contrast to binary classification, we keep all the images as CNN can perform multiclass classification. In addition, instead of Scikit-Learn we use *Keras API* for building our model instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JUJLZ_gHYWKO"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_CNN_dataset(normalized_train_images, train_labels)\n",
    "X_test, y_test = prepare_CNN_dataset(normalized_test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j2HC_zp24MvN"
   },
   "source": [
    "#### Model selection\n",
    "We use Keras API to build our CNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "colab_type": "code",
    "id": "dhLwn31tTeMh",
    "outputId": "b2a01703-45af-4819-d1b4-db4e17e3e0af"
   },
   "outputs": [],
   "source": [
    "# Number of kernels in each layer\n",
    "# For instance, [64, 32] means 64 filters in first layer, 32 filters in the second layer\n",
    "nbr_filters = [2, 2] \n",
    "\n",
    "# The shape of all kernels (e.g. in previous assignment you defined a 2x2 kernel)\n",
    "kernel_shape = (3, 3) # \n",
    "\n",
    "# Number of nodes in each fully-connected layer\n",
    "nbr_nodes = [4, 4]\n",
    "\n",
    "# Build model\n",
    "model = build_CNN(nbr_filters=nbr_filters, \n",
    "                  kernel_shape=kernel_shape, \n",
    "                  nbr_nodes=nbr_nodes)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z5GYLZcL4PET"
   },
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "c5bXrAwKUpeY",
    "outputId": "35615697-a31e-4074-c2a8-d36d961e64de"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ROW5FY0O4Uqs"
   },
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uAugKKa1aLOS",
    "outputId": "66675357-547f-4796-8104-a99d53d4b2ca"
   },
   "outputs": [],
   "source": [
    "print(\"############################ MODEL EVALUATION ############################\")\n",
    "train_predictions = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train.argmax(axis=1), train_predictions.argmax(axis=1))\n",
    "\n",
    "test_predictions = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test.argmax(axis=1), test_predictions.argmax(axis=1))\n",
    "\n",
    "print(f\"Train accuracy: {100*train_accuracy}%\")\n",
    "print(f\"Test accuracy: {100*test_accuracy}%\")\n",
    "print_confusion_matrices(y_test.argmax(axis=1), test_predictions.argmax(axis=1), class_names=label_to_article.values());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ky9sHbgL47mD"
   },
   "source": [
    "### ASSIGNMENT 7:\n",
    "- Modify the code and try to improve the performance of the CNN model.\n",
    "\n",
    "**Q 7.1:** What is the highest test accuracy you got for CNN? Compare the results to the best ANN model. \n",
    "\n",
    " \n",
    "\n",
    "**Q 7.2:** By comparing the performance of the CNN with the performance of the ANN. Which model is suitable for the Zalando dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "colab_type": "code",
    "id": "CAaGYINhaY-7",
    "outputId": "d5aa1db6-df57-4369-d03e-095520f27729"
   },
   "outputs": [],
   "source": [
    "############ FILL IN YOUR CODE BELOW ##########################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############ FILL IN YOUR CODE ABOCE #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GrhonNtqHIzC",
    "outputId": "d935fd0d-cae2-4f01-93bd-2d9ea04bb35d"
   },
   "outputs": [],
   "source": [
    "# Evaluation script\n",
    "print(\"############################ MODEL EVALUATION ############################\")\n",
    "train_predictions = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train.argmax(axis=1), train_predictions.argmax(axis=1))\n",
    "\n",
    "test_predictions = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test.argmax(axis=1), test_predictions.argmax(axis=1))\n",
    "\n",
    "print(f\"Train accuracy: {100*train_accuracy}%\")\n",
    "print(f\"Test accuracy: {100*test_accuracy}%\")\n",
    "print_confusion_matrices(y_test.argmax(axis=1), test_predictions.argmax(axis=1), class_names=label_to_article.values());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rIRITMqdlE4I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tutorial_ZARA_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
